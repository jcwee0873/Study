{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Embedding Layer?\n",
    "- Word2Vec, FastText 등 fix된 vector를 넣어줄 경우, 해당 알고리즘의 objective에 최적화 될 뿐,  \n",
    "원하는 task에 최적화된 가중치를 가지지 않음\n",
    "- Embedding -> Linear -> Activation -> Layer ...\n",
    "- Linear + Linear = Linear\n",
    "- 단, Embedding Layer의 경우 one-hot vector 처리에 최적화된 구조\n",
    "- 효율적인 계산이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding\n",
    "- SentenceEmbeddingVector = sigma WordEmbeddingVector ??\n",
    "- 문장내 어순의 차이(word vector는 동일)가 다른 의미를 가지기 때문에 좋지 않음\n",
    "- 단어는 context의 영향을 받기 때문에, 이를 고려한 Embedding이 필요\n",
    "- RNN, Seq2seq 등을 활용(Context Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
