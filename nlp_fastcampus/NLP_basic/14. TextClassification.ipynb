{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "- 문장의 context를 바탕으로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        hidden_size,\n",
    "        n_classes,\n",
    "        n_layers=4,\n",
    "        dropout_p=.3\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.generator = nn.Linear(hidden_size * 2, n_classes)\n",
    "        # Use LogSoftmax + NLLLoss\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # |x| = (batch_size, length, word_vec_size)\n",
    "        x, _ = self.rnn(x)\n",
    "        # |x| = (batch_size, length, hidden_size * 2)\n",
    "        # |x[:,-1]| = (bs, 1, hidden_size * 2)\n",
    "        y = self.activation(self.generator(x[:, -1]))\n",
    "        # |y| = (batch_size, n_classes)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "- 문장 내 단어의 패턴을 인식\n",
    "- x -> Embedding\n",
    "  - |CNN_input| = (length, word_vec_size)\n",
    "  - |kernel_size| = (#filters, windows, word_vec_size)\n",
    "  - |CNN_output| = (#filters, length - windows + 1, 1)\n",
    "  - ` windows = 패턴 내 단어의 갯수, hyperparameter\n",
    "- CNN -> Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        word_vec_size,\n",
    "        n_classes,\n",
    "        use_batch_norm=False,\n",
    "        dropout_p=.5,\n",
    "        window_sizes=[3, 4, 5],\n",
    "        n_filters=[100, 100, 100]\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.n_classes = n_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "        # window_size = how many words a pattern cover\n",
    "        self.window_sizes = window_sizes\n",
    "        # n_filters = how many patterns to cover\n",
    "        self.n_filters = n_filters\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        # Use nn.ModuleList to register each sub-modules\n",
    "        # 단순 list에 담을경우, module에서 layer로 인식을 못해서 optimizer에서 parameter를 못가져옴\n",
    "        self.feature_extractors = nn.ModuleList()\n",
    "\n",
    "        for window_size, n_filter in zip(window_sizes, n_filters):\n",
    "            self.feature_extractors.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=1, # 만약 컬러그림이었으면 3채널\n",
    "                        out_channels=n_filter,\n",
    "                        kernel_size=(window_size, word_vec_size),\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm2d(n_filter) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "                )\n",
    "            )\n",
    "                                  # 차후에 concat 해서 진행할 거라서\n",
    "        self.generator = nn.Linear(sum(n_filters), n_classes)\n",
    "        self.activation= nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # |x| = (batch_size, length, word_Vec_size)\n",
    "        min_length = max(self.window_sizes)\n",
    "        if min_length > x.size(1):\n",
    "            # .new() x와 같은 tensor 타입, 같은 device에 있는 tnesor 생성\n",
    "            pad = x.new(x.size(0), min_length - x.size(1), self.word_vec_size).zero_()\n",
    "            # |pad| = (batch_size, min_length - length, word_vec_size)\n",
    "            x = torch.cat([x, pad], dim=1)\n",
    "            # |x| = (batch_size, min_length, word_vec_size)\n",
    "        \n",
    "        # cnn의 적용을 위해 적절한 shape로 바꿔줌\n",
    "        # self.Conv2d에서 in_channel 1로 지정한 이유\n",
    "        x = x.unsqueeze(1)\n",
    "        # |x| = (batch_size, 1, length, word_vec_size)\n",
    "\n",
    "        cnn_outs = []\n",
    "        for block in self.feature_extractors:\n",
    "            cnn_out = block(x)\n",
    "            # |cnn_out| = (batch_size, n_filter, length - window_size + 1, 1)\n",
    "            \n",
    "            # 학습하는 layer가 아니기 때문에 functional로 선언 가능\n",
    "            cnn_out = nn.functional.max_pool1d(\n",
    "                input=cnn_out.squeeze(-1),\n",
    "                kernel_size=cnn_out.size(-2) # (batch_size, n_filter, 1)\n",
    "            ).squeeze(-1)\n",
    "            # |cnn_out| = (batch_size, n_filter)\n",
    "            cnn_outs += [cnn_out]\n",
    "        cnn_outs = torch.cat(cnn_outs, dim=-1)\n",
    "        # |cnn_outs| = (batch_size, sum(n_filters))\n",
    "        y = self.activation(self.generator(cnn_outs))\n",
    "        # |y| = (batch_size, n_classes)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "VERBOSE_SILENT = 0\n",
    "VERBOSE_EPOCH_WISE = 1\n",
    "VERBOSE_BATCH_WISE = 2\n",
    "\n",
    "\n",
    "class MyEngine(Engine):\n",
    "\n",
    "    def __init__(self, func, model, crit, optimizer, config):\n",
    "        # Ignite Engine does not have objects in below lines.\n",
    "        # Thus, we assign class variables to access these object, during the procedure.\n",
    "        self.model = model\n",
    "        self.crit = crit\n",
    "        self.optimizer = optimizer\n",
    "        self.config = config\n",
    "\n",
    "        super().__init__(func) # Ignite Engine only needs function to run.\n",
    "\n",
    "        self.best_loss = np.inf\n",
    "        self.best_model = None\n",
    "\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    @staticmethod\n",
    "    def train(engine, mini_batch):\n",
    "        # You have to reset the gradients of all model parameters\n",
    "        # before to take another step in gradient descent.\n",
    "        engine.model.train() # Because we assign model as class variable, we can easily access to it.\n",
    "        engine.optimizer.zero_grad()\n",
    "\n",
    "        x, y = mini_batch.text, mini_batch.label\n",
    "        x, y = x.to(engine.device), y.to(engine.device)\n",
    "        \n",
    "        # 정제되지 않은 text여서, 무의미하게 긴 문장 축소\n",
    "        x = x[:, :engine.config.max_length]\n",
    "\n",
    "        # Take feed-forward\n",
    "        y_hat = engine.model(x)\n",
    "\n",
    "        loss = engine.crit(y_hat, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate accuracy only if 'y' is LongTensor,\n",
    "        # which means that 'y' is one-hot representation.\n",
    "        if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "            accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "        else:\n",
    "            accuracy = 0\n",
    "\n",
    "        # Take a step of gradient descent.\n",
    "        engine.optimizer.step()\n",
    "\n",
    "        return {\n",
    "            'loss': float(loss),\n",
    "            'accuracy': float(accuracy),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def validate(engine, mini_batch):\n",
    "        engine.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = mini_batch.text, mini_batch.label\n",
    "            x, y = x.to(engine.device), y.to(engine.device)\n",
    "\n",
    "            x = x[:, :engine.config.max_length]\n",
    "\n",
    "            y_hat = engine.model(x)\n",
    "\n",
    "            loss = engine.crit(y_hat, y)\n",
    "\n",
    "            if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "                accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "            else:\n",
    "                accuracy = 0\n",
    "\n",
    "        return {\n",
    "            'loss': float(loss),\n",
    "            'accuracy': float(accuracy),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def attach(train_engine, validation_engine):\n",
    "        def attach_running_average(engine, metric_name):\n",
    "            RunningAverage(output_transform=lambda x: x[metric_name]).attach(\n",
    "                engine,\n",
    "                metric_name,\n",
    "            )\n",
    "\n",
    "\n",
    "        training_metric_names = ['loss', 'accuracy']\n",
    "\n",
    "        for metric_name in training_metric_names:\n",
    "            attach_running_average(train_engine, metric_name)\n",
    "\n",
    "        # If the verbosity is set, progress bar would be shown for mini-batch iterations.\n",
    "        # Without ignite, you can use tqdm to implement progress bar.\n",
    "        pbar = ProgressBar(bar_format=None, ncols=120)\n",
    "        pbar.attach(train_engine, training_metric_names)\n",
    "\n",
    "        # If the verbosity is set, statistics would be shown after each epoch.\n",
    "        @train_engine.on(Events.EPOCH_COMPLETED)\n",
    "        def print_train_logs(engine):\n",
    "            print('Epoch {} - loss={:.4e} accuracy={:.4f}'.format(\n",
    "                engine.state.epoch,\n",
    "                engine.state.metrics['loss'],\n",
    "                engine.state.metrics['accuracy'],\n",
    "            ))\n",
    "\n",
    "\n",
    "        validation_metric_names = ['loss', 'accuracy']\n",
    "\n",
    "        for metric_name in validation_metric_names:\n",
    "            attach_running_average(validation_engine, metric_name)\n",
    "            \n",
    "        # Do same things for validation engine.\n",
    "        pbar = ProgressBar(bar_format=None, ncols=120)\n",
    "        pbar.attach(validation_engine, validation_metric_names)\n",
    "\n",
    "        @validation_engine.on(Events.EPOCH_COMPLETED)\n",
    "        def print_valid_logs(engine):\n",
    "            print('Validation - loss={:.4e} accuracy={:.4f} best_loss={:.4e}'.format(\n",
    "                engine.state.metrics['loss'],\n",
    "                engine.state.metrics['accuracy'],\n",
    "                engine.best_loss,\n",
    "            ))\n",
    "\n",
    "    @staticmethod\n",
    "    def check_best(engine):\n",
    "        loss = float(engine.state.metrics['loss'])\n",
    "        if loss <= engine.best_loss: # If current epoch returns lower validation loss,\n",
    "            engine.best_loss = loss  # Update lowest validation loss.\n",
    "            engine.best_model = deepcopy(engine.model.state_dict()) # Update best model weights.\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(engine, train_engine, config, **kwargs):\n",
    "        torch.save(\n",
    "            {\n",
    "                'model': engine.best_model,\n",
    "                'config': config,\n",
    "                **kwargs\n",
    "            }, config.model_fn\n",
    "        )\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model, crit, optimizer,\n",
    "        train_loader, valid_loader,\n",
    "    ):\n",
    "        train_engine = MyEngine(\n",
    "            MyEngine.train,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "        validation_engine = MyEngine(\n",
    "            MyEngine.validate,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "\n",
    "        MyEngine.attach(\n",
    "            train_engine,\n",
    "            validation_engine\n",
    "        )\n",
    "\n",
    "        def run_validation(engine, validation_engine, valid_loader):\n",
    "            validation_engine.run(valid_loader, max_epochs=1)\n",
    "\n",
    "        train_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            run_validation, # function\n",
    "            validation_engine, valid_loader, # arguments\n",
    "        )\n",
    "        validation_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            MyEngine.check_best, # function\n",
    "        )\n",
    "        # validation_engine.add_event_handler(\n",
    "        #     Events.EPOCH_COMPLETED,\n",
    "        #     MyEngine.save_model,\n",
    "        #     train_engine, self.config,\n",
    "        # )\n",
    "\n",
    "        train_engine.run(\n",
    "            train_loader,\n",
    "            max_epochs=self.config.n_epochs,\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(validation_engine.best_model)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "version = list(map(int, torchtext.__version__.split('.')))\n",
    "if version[0] <= 0 and version[1] < 9:\n",
    "    from torchtext import data\n",
    "else:\n",
    "    from torchtext.legacy import data\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(\n",
    "        self, train_fn,\n",
    "        batch_size=64,\n",
    "        valid_ratio=.2,\n",
    "        device=-1,\n",
    "        max_vocab=999999,\n",
    "        min_freq=1,\n",
    "        use_eos=False,\n",
    "        shuffle=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define field of the input file.\n",
    "        # The input file consists of two fields.\n",
    "        self.label = data.Field(\n",
    "            sequential=False,\n",
    "            use_vocab=True,\n",
    "            unk_token=None\n",
    "        )\n",
    "        self.text = data.Field(\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=False,\n",
    "            eos_token='<EOS>' if use_eos else None,\n",
    "        )\n",
    "        # Those defined two columns will be delimited by TAB.\n",
    "        # Thus, we use TabularDataset to load two columns in the input file.\n",
    "        # We would have two separate input file: train_fn, valid_fn\n",
    "        # Files consist of two columns: label field and text field.\n",
    "        train, valid = data.TabularDataset(\n",
    "            path=train_fn,\n",
    "            format='tsv', \n",
    "            fields=[\n",
    "                ('label', self.label),\n",
    "                ('text', self.text),\n",
    "            ],\n",
    "        ).split(split_ratio=(1 - valid_ratio))\n",
    "        \n",
    "        # Those loaded dataset would be feeded into each iterator:\n",
    "        # train iterator and valid iterator.\n",
    "        # We sort input sentences by length, to group similar lengths.\n",
    "        self.train_loader, self.valid_loader = data.BucketIterator.splits(\n",
    "            (train, valid),\n",
    "            batch_size=batch_size,\n",
    "            device='cuda:%d' % device if device >= 0 else 'cpu',\n",
    "            shuffle=shuffle,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            sort_within_batch=True,\n",
    "        )\n",
    "\n",
    "        # At last, we make a vocabulary for label and text field.\n",
    "        # It is making mapping table between words and indice.\n",
    "        self.label.build_vocab(train)\n",
    "        self.text.build_vocab(train, max_size=max_vocab, min_freq=min_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train| = 118314 |valid| = 29579\n",
      "|vocab| = 12986 |classes| = 2\n",
      "RNNClassifier(\n",
      "  (emb): Embedding(12986, 256)\n",
      "  (rnn): LSTM(256, 512, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (generator): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  (activation): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3b0623c0c1499f821c90165a60ba9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss=2.1011e-01 accuracy=0.9242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27dd28e812e4f608d343d1432559038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.7917e-01 accuracy=0.9362 best_loss=inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032338b8cdd7491ba5ac24f017dfd5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss=1.7959e-01 accuracy=0.9374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f8f860b61f406181dd08e8c5710265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.5846e-01 accuracy=0.9441 best_loss=1.7917e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feba8fd775a4af490fa5313044f75a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss=1.5974e-01 accuracy=0.9445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b17993a10de4a2fa75ed587be13b589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.4590e-01 accuracy=0.9484 best_loss=1.5846e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c128f549e0144deeb533e4b839a8e984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss=1.4941e-01 accuracy=0.9506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ed19f45814901ae78f532a2c60644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.6026e-01 accuracy=0.9485 best_loss=1.4590e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c867005971274db39cc102a87c1b3180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss=1.0395e-01 accuracy=0.9659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf5687b51504452b50d24db1c561c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.6445e-01 accuracy=0.9479 best_loss=1.4590e-01\n",
      "CNNClassifier(\n",
      "  (emb): Embedding(12986, 256)\n",
      "  (feature_extractors): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 100, kernel_size=(3, 256), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(1, 100, kernel_size=(4, 256), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(1, 100, kernel_size=(5, 256), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=300, out_features=2, bias=True)\n",
      "  (activation): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b06ea5c5154e0bb58967d4d52a5330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss=2.1976e-01 accuracy=0.9208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c98e0ac3824d589de5b3910e8554b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=3.2039e-01 accuracy=0.8795 best_loss=inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cb3f56f86448649d9490bb21c085c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss=1.7260e-01 accuracy=0.9406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8efd407cea041f8a50c6675fc8e5d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=2.0270e-01 accuracy=0.9227 best_loss=3.2039e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79932f385b74a488bf22d64d13816f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss=1.5276e-01 accuracy=0.9469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5c22d9b0994f4799ba318bafebca99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=4.0785e-01 accuracy=0.8642 best_loss=2.0270e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5ed867cd6c4de0b04e758d2c38a14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss=1.1788e-01 accuracy=0.9605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f51bba5744e1ab5fad87139a493eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=3.4233e-01 accuracy=0.8921 best_loss=2.0270e-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5038e47fcb34b1baccb98cfd1801601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                           | 1/925 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss=9.4036e-02 accuracy=0.9661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee9c737d0864c6bbec0ee3c33c84603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|3                                                                                          | 1/232 [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=3.0412e-01 accuracy=0.9076 best_loss=2.0270e-01\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Arg :\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_fn = './model.pth'\n",
    "        self.train_fn = './review.sorted.uniq.refined.tok.shuf.train.tsv'\n",
    "        self.gpu_id = 0\n",
    "        self.min_vocab_freq = 5\n",
    "        self.max_vocab_size = 999999\n",
    "        self.batch_size = 128\n",
    "        self.n_epochs = 5\n",
    "        self.word_vec_size = 256\n",
    "        self.hidden_size = 512\n",
    "        self.n_layers = 4\n",
    "        self.dropout = .3\n",
    "        self.max_length = 256\n",
    "        self.rnn = True\n",
    "        self.cnn = True\n",
    "        self.use_batch_norm = True\n",
    "        self.window_sizes = [3, 4, 5]\n",
    "        self.n_filters = [100, 100, 100]\n",
    "\n",
    "def main(config):\n",
    "    loaders = DataLoader(\n",
    "        train_fn=config.train_fn,\n",
    "        batch_size=config.batch_size,\n",
    "        min_freq=config.min_vocab_freq,\n",
    "        max_vocab=config.max_vocab_size,\n",
    "        device=config.gpu_id\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        '|train| =', len(loaders.train_loader.dataset),\n",
    "        '|valid| =', len(loaders.valid_loader.dataset),\n",
    "    )\n",
    "    \n",
    "    vocab_size = len(loaders.text.vocab)\n",
    "    n_classes = len(loaders.label.vocab)\n",
    "    print('|vocab| =', vocab_size, '|classes| =', n_classes)\n",
    "\n",
    "    if config.rnn is False and config.cnn is False:\n",
    "        raise Exception('You need to specify an architecture to train. (--rnn or --cnn)')\n",
    "\n",
    "    if config.rnn:\n",
    "        # Declare model and loss.\n",
    "        model = RNNClassifier(\n",
    "            input_size=vocab_size,\n",
    "            word_vec_size=config.word_vec_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            n_classes=n_classes,\n",
    "            n_layers=config.n_layers,\n",
    "            dropout_p=config.dropout,\n",
    "        )\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        crit = nn.NLLLoss()\n",
    "        print(model)\n",
    "\n",
    "        if config.gpu_id >= 0:\n",
    "            model.cuda(config.gpu_id)\n",
    "            crit.cuda(config.gpu_id)\n",
    "\n",
    "        rnn_trainer = Trainer(config)\n",
    "        rnn_model = rnn_trainer.train(\n",
    "            model,\n",
    "            crit,\n",
    "            optimizer,\n",
    "            loaders.train_loader,\n",
    "            loaders.valid_loader\n",
    "        )\n",
    "    if config.cnn:\n",
    "        # Declare model and loss.\n",
    "        model = CNNClassifier(\n",
    "            input_size=vocab_size,\n",
    "            word_vec_size=config.word_vec_size,\n",
    "            n_classes=n_classes,\n",
    "            use_batch_norm=config.use_batch_norm,\n",
    "            dropout_p=config.dropout,\n",
    "            window_sizes=config.window_sizes,\n",
    "            n_filters=config.n_filters,\n",
    "        )\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        crit = nn.NLLLoss()\n",
    "        print(model)\n",
    "\n",
    "        if config.gpu_id >= 0:\n",
    "            model.cuda(config.gpu_id)\n",
    "            crit.cuda(config.gpu_id)\n",
    "\n",
    "        cnn_trainer = Trainer(config)\n",
    "        cnn_model = cnn_trainer.train(\n",
    "            model,\n",
    "            crit,\n",
    "            optimizer,\n",
    "            loaders.train_loader,\n",
    "            loaders.valid_loader\n",
    "        )\n",
    "\n",
    "    torch.save({\n",
    "        'rnn': rnn_model.state_dict() if config.rnn else None,\n",
    "        'cnn': cnn_model.state_dict() if config.cnn else None,\n",
    "        'config': config,\n",
    "        'vocab': loaders.text.vocab,\n",
    "        'classes': loaders.label.vocab,\n",
    "    }, config.model_fn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Arg()\n",
    "    main(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 907.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\t생 각   보 다   밝   아 요   ㅎ ㅎ\n",
      "negative\t쓸   대   가   없   네 요\n",
      "negative\t깔   금   해 요   .   가 벼 워   요   .   설 치   가   쉬 워 요   .   타   사 이 트   에   비 해   가 격   도   저 렴   하   답 니 다   .\n",
      "negative\t크 기   나   두 께   가   딱   제   가   원   하   던   사 이 즈   네 요   .   책 상   의 자   가   너 무   딱 딱   해 서   쿠 션   감   좋   은   방 석   이   필 요   하   던   차   에   좋   은   제 품   만 났   네 요   .   냄 새   얘 기   하   시   는   분   도   더 러   있   던 데   별 로   냄 새   안   나   요   .\n",
      "positive\t빠 르   고   괜 찬   습 니 다   .\n",
      "positive\t유 통   기 한   도   넉 넉   하   고   좋   아 요\n",
      "positive\t좋   은   가 격   에   좋   은   상 품   잘   쓰   겠   습 니 다   .\n",
      "negative\t사 이 트   에 서   늘   생 리 대   사   서   쓰   는 데   오 늘   처 럼   이 렇 게   비 닐   에   포 장   되   어   받   아   본   건   처 음   입 니 다   .   위 생   용 품   이   고   자 체   도   비 닐   포 장   이   건 만   소 형   박 스   에   라 도   넣   어   보 내   주   시   지   .   . .\n",
      "negative\t연 결   부 분   이   많 이   티   가   납 니 다   .   재 질   구 김   도   좀   있   습 니 다   .\n",
      "negative\t애 기   태 열   때 문   에   구 매   해 서   잘   쓰   고   있   습 니 다   .\n",
      "positive\t항 상   쓰   던   거   라   만 족   합 니 다   .   항 상   쓰   던   거   라   만 족   합 니 다   .\n",
      "negative\t자   ~ ~ ~   알   쓰   겠   습 니 다   .\n",
      "negative\t등 기   구   매 번   깜 빡 이   고   갈   고   그 랬   는 데   .   .   이 거   하   면   안   그 러   겠   죠   .   .\n",
      "negative\t케 이 스   잘   받   았   습 니 다\n",
      "positive\t빠 른   배 송   에   잘   씻 기   고   좋   아 요   ^ . ^\n",
      "negative\t저 렴   한   금 액   으 로   잘   삿   습 니 다\n",
      "negative\t갤   8   유   ㅓ ㅇ 저 임   상 단   터 치   잘   안   됨   왜 냐 면   들 떠 서   자 증   남   .   즈   짜 증   남\n",
      "negative\t재 고   가   없   어 서   취 소   후   재   주 문   들 어 가   서   늦   었   기   도   하   지 만   ,   택 배   사   를   두   곳   을   통 해   배 송   해 서   도 착   시 간   이   두   곳   이   다 르   고   ,   설 치   도   지 연   되   고   불 편   했   네 요   .   주 문   시   한   번   에   잘   하   세 요   .\n",
      "negative\t배 송   은   빠 르   고   좋   았   으 나   제   가   주 문   한   것   은   블 랙   마 블   을   주 문   했   는 데   블 랙   단 색   이   왔 어 요   주   믄 서   는   제 대 로   확 인   안   하   시   나 요   ?   ?   가 격   이   다 르   면   교 환   요 청   했   겠   지 만   가 격   은   동 일   하   기   에   그 냥   쓰   려 고   합 니 다   폼   블 러   야   헬 스   장   에 서   매 일   사 용   하   던   거   라   집   에 서   도   하   려 고   주 문   한   거   라   크   게   쓸   장 점   이   .   . .   다 만   이 곳   에 선   주 문 서   확 인   이   엉 망   이   란   건   확 인   했   네 요\n",
      "negative\t이 거   까   니 까   베 란 다   가   깔 끔   해 졌   어 요\n",
      "positive\t순 하   고   좋   은   것   같   아 요   .   믿   고   쓰   는   제 품   이   에 요\n",
      "negative\t별 루   네 요   .   . .   비 누 칠   을   해 도   거 품   이   나   지   도   않   고   .   . .\n",
      "negative\t항 상   구 매   하   는   곳   그 러 나   이 번   에   는   실 패   다   브 라 질   커 피   뭔   이 런   맛   이   나   냐   역 시   싸   게   파   는   것   은   이 유   가   있   나   보 다   이 번   이 벤 트   는   당 한   거   같   음\n",
      "negative\t접 착 력   너 무   심 하   네 요   .   벽 지   빡 빡   닦   아 서   붙   혔   는 데   도   전 부   떨 어 지   더 니   집   에   있   는   테 이 프   로   다 시   해 서   붙   혔   는 데   또   떨 어 지   니   .   뭘 로   붙 혀   야   하 나   .   .   처 음   부 터   좀   더   강 한   테 이 핑   처 리   를   해   주   심   좋   을   거   같   은 데   .   .   노 동 력   이   더   드   네 요   .   타 일   같   은   벽   은   좀   나   을   거   같   긴   한 데   벽 지   에   잘   붙   어 야 죠   ㅡ ㅡ   내   것   만   접 착 력   이   더   떨 어 지   는   건 지   ~\n",
      "positive\t깔 끔   하   고   정 말   좋   아 요\n",
      "positive\t너 무   좋   아 요   너 무   좋   아 요   럼   ㄻ ㄹ 미 ㅏ ㄹ 마 ㅏ 힌 어 ㅏ 런 아 르 ㅏ 룸 룸 ㄴ ㅇ 머 이 ㅓ ㅣ ㅓ ㅇ   너 무   좋   아 요   너 무   좋   아 요   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ ㅋ   ㅋ ㅋ\n",
      "negative\t암 막   커 튼   이 랑   레 이 스   커 튼   이 랑   사 이 즈   가   틀 려 요   ~   길 이   도   그 렇   고   폭   도   안   맞   고   ,   그 냥   귀 찮   아 서   써 요   .\n",
      "negative\ts d f s d f s d f d\n",
      "negative\t상 품   자 체   는   알   던   거   라   상 관   없   는 데   포 장   도   안   되   어   있   고   쇼 핑 백   도   없   더 라 구 요   ; ;   이 것   만   지 금   까 지   몇   개   째   구 매   인 데   이 렇 게   덜 렁   상 품   만   온   경 우   는   처 음   이   라   당 황   스 럽   네 요   .\n",
      "negative\t갯   수   가   너 무   적   네 요   잘   먹   지   도   않   네 요\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_text():\n",
    "    lines = []\n",
    "\n",
    "    with open('./review.sorted.uniq.refined.tok.shuf.test.tsv', 'r') as f:\n",
    "        for line in f.readlines() :\n",
    "            lines += [line.split('\\t')[1].strip()]\n",
    "\n",
    "    # for line in sys.stdin:\n",
    "    #     if line.strip() != '':\n",
    "    #         lines += [line.strip().split(' ')]\n",
    "    return lines[:30]\n",
    "\n",
    "def define_field():\n",
    "    return (\n",
    "        data.Field(\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=False,\n",
    "        ),\n",
    "        data.Field(\n",
    "            sequential=False,\n",
    "            use_vocab=True,\n",
    "            unk_token=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "def main(config):\n",
    "    saved_data = torch.load(\n",
    "        './model.pth',\n",
    "        map_location='cuda:0'\n",
    "    )\n",
    "\n",
    "    train_config = saved_data['config']\n",
    "    rnn_best = saved_data['rnn']\n",
    "    cnn_best = saved_data['cnn']\n",
    "    vocab = saved_data['vocab']\n",
    "    classes = saved_data['classes']\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    text_field, label_field = define_field()\n",
    "    text_field.vocab = vocab\n",
    "    label_field.vocab = classes\n",
    "\n",
    "    lines = read_text()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # convert string to index(one-hot vector 인덱스로 받아옴)\n",
    "        x = text_field.numericalize(\n",
    "            text_field.pad(lines),\n",
    "            device='cuda:0'\n",
    "        )\n",
    "\n",
    "        ensemble = []\n",
    "\n",
    "        if rnn_best is not None:\n",
    "            model = RNNClassifier(\n",
    "                input_size=vocab_size,\n",
    "                word_vec_size=train_config.word_vec_size,\n",
    "                hidden_size=train_config.hidden_size,\n",
    "                n_classes=n_classes,\n",
    "                n_layers=train_config.n_layers,\n",
    "                dropout_p=train_config.dropout\n",
    "            )\n",
    "            model.load_state_dict(rnn_best)\n",
    "            ensemble += [model]\n",
    "\n",
    "        if cnn_best is not None:\n",
    "            model = CNNClassifier(\n",
    "                input_size=vocab_size,\n",
    "                word_vec_size=train_config.word_vec_size,\n",
    "                n_classes=n_classes,\n",
    "                use_batch_norm=train_config.use_batch_norm,\n",
    "                dropout_p=train_config.dropout,\n",
    "                window_sizes=train_config.window_sizes,\n",
    "                n_filters=train_config.n_filters\n",
    "            )\n",
    "            model.load_state_dict(cnn_best)\n",
    "            ensemble += [model]\n",
    "\n",
    "        y_hats = []\n",
    "\n",
    "        for model in ensemble:\n",
    "            model.cuda(0)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            y_hat = []\n",
    "            for idx in tqdm(range(0, len(lines), 32)):\n",
    "                y_hat += [model(x[idx:idx + 32])]\n",
    "            y_hat = torch.cat(y_hat, dim=0)\n",
    "            # |y_hat| = (len(lines), n_classes)\n",
    "\n",
    "            y_hats += [y_hat]\n",
    "\n",
    "        y_hats = torch.stack(y_hats).exp()\n",
    "\n",
    "        y_hats = y_hats.sum(dim=0) / len(ensemble)\n",
    "\n",
    "        probs, indice = y_hats.cpu().topk(1)\n",
    "        for i in range(len(lines)):\n",
    "            sys.stdout.write('%s\\t%s\\n' % (\n",
    "                ' '.join([classes.itos[indice[i]]]),\n",
    "                ' '.join(lines[i]))\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "452df0821433779ea0d62ff49f1a7cc03808e7ef127810619f5ecf0887789e09"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
